#!/usr/bin/env node

/**
 * Phase 3 Sprint 2 - Task 5: Performance Scaling & Load Testing
 * 
 * Batch processing pipeline for cohort optimization
 * - Streams 1M+ learner dataset through clustering
 * - Measures throughput (learners/minute)
 * - Validates <200ms SLA per batch
 * - Tests horizontal scaling (worker nodes)
 * 
 * Usage:
 *   node scripts/optimization-scaling-tests.js --batch-size=1000 --total-learners=10000
 *   node scripts/optimization-scaling-tests.js --load-test --scale=1000000
 *   node scripts/optimization-scaling-tests.js --workers=4 --duration=60
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { discoverCohortsOptimized } from '../engine/cohort-analyzer-optimized.js';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

/**
 * Configuration
 */
const CONFIG = {
  BATCH_SIZE: parseInt(process.env.BATCH_SIZE || '1000'),
  TOTAL_LEARNERS: parseInt(process.env.TOTAL_LEARNERS || '10000'),
  MAX_WORKERS: parseInt(process.env.MAX_WORKERS || '4'),
  CACHE_SIZE_MB: parseInt(process.env.CACHE_SIZE_MB || '512'),
  SLA_MS: 200, // Target latency per batch
  WARMUP_BATCHES: 2,
};

/**
 * In-memory cache for cohort results (simulates Redis)
 */
class SimpleCache {
  constructor(maxItems = 10000) {
    this.cache = new Map();
    this.maxItems = maxItems;
    this.hits = 0;
    this.misses = 0;
  }

  set(key, value) {
    if (this.cache.size >= this.maxItems) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }
    this.cache.set(key, { value, timestamp: Date.now() });
  }

  get(key) {
    if (this.cache.has(key)) {
      this.hits++;
      return this.cache.get(key).value;
    }
    this.misses++;
    return null;
  }

  hitRate() {
    const total = this.hits + this.misses;
    return total === 0 ? 0 : (this.hits / total) * 100;
  }

  clear() {
    this.cache.clear();
    this.hits = 0;
    this.misses = 0;
  }
}

/**
 * Generate synthetic learner dataset
 */
function* generateLearnersStream(count, archetype = null) {
  const archetypes = ['fast-learner', 'specialist', 'power-user', 'retainer', 'generalist'];
  const domains = ['design', 'data', 'devops', 'frontend', 'backend', 'qa'];

  for (let i = 0; i < count; i++) {
    const arch = archetype || archetypes[i % archetypes.length];
    const userId = `learner_${i}_${arch}`;
    const conversations = [];

    // Generate 8 weeks of conversation history
    let conversationCount = 0;
    for (let w = 0; w < 8; w++) {
      let weeksCapabilities = 1;
      
      if (arch === 'fast-learner') weeksCapabilities = 8 + Math.random() * 4;
      else if (arch === 'specialist') weeksCapabilities = 4 + Math.random() * 2;
      else if (arch === 'power-user') weeksCapabilities = 10 + Math.random() * 5;
      else if (arch === 'retainer') weeksCapabilities = 3 + Math.random() * 2;
      else weeksCapabilities = 2 + Math.random() * 2;

      for (let c = 0; c < Math.ceil(weeksCapabilities); c++) {
        conversations.push({
          conversationId: `conv_${i}_${w}_${c}`,
          timestamp: Date.now() - (8 - w) * 7 * 24 * 60 * 60 * 1000 + Math.random() * 7 * 24 * 60 * 60 * 1000,
          capabilityId: `cap_${Math.floor(Math.random() * 25)}`,
          domain: domains[Math.floor(Math.random() * domains.length)],
          interactions: 3 + Math.floor(Math.random() * 8),
          rating: 3.5 + Math.random() * 1.5
        });
      }
    }

    yield { userId, conversations };
    
    if ((i + 1) % 1000 === 0) {
      process.stderr.write(`  Generated ${i + 1} learners...\r`);
    }
  }
}

/**
 * Process batch of learners through cohort discovery
 */
async function processBatch(learners, cache) {
  const userConversationMap = {};
  const cacheKey = `batch_${Date.now()}`;

  // Check cache
  const cachedResult = cache.get(cacheKey);
  if (cachedResult) {
    return cachedResult;
  }

  // Build user map
  for (const { userId, conversations } of learners) {
    userConversationMap[userId] = conversations;
  }

  // Process through cohort analyzer
  const t0 = performance.now();
  const result = await discoverCohortsOptimized(userConversationMap);
  const duration = performance.now() - t0;

  // Cache result
  const cohortData = {
    cohortCount: result.cohorts?.length || 0,
    userCount: learners.length,
    duration,
    timestamp: new Date().toISOString(),
    cohorts: result.cohorts || []
  };
  
  cache.set(cacheKey, cohortData);

  return cohortData;
}

/**
 * Run batch throughput test
 */
async function runThroughputTest() {
  console.log('\nðŸ“Š Batch Processing Throughput Test');
  console.log('='.repeat(60));
  console.log(`Batch Size: ${CONFIG.BATCH_SIZE} learners`);
  console.log(`Total Learners: ${CONFIG.TOTAL_LEARNERS}`);
  console.log(`Cache Size: ${CONFIG.CACHE_SIZE_MB}MB`);
  console.log('');

  const cache = new SimpleCache(10000);
  const metrics = {
    totalBatches: 0,
    successfulBatches: 0,
    failedBatches: 0,
    totalTime: 0,
    minTime: Infinity,
    maxTime: 0,
    batchTimes: [],
    slaBreach: 0
  };

  // Warmup batches
  console.log(`ðŸ”¥ Warming up (${CONFIG.WARMUP_BATCHES} batches)...`);
  for (let i = 0; i < CONFIG.WARMUP_BATCHES; i++) {
    const learners = Array.from(generateLearnersStream(CONFIG.BATCH_SIZE));
    await processBatch(learners, cache);
  }

  // Actual test
  const totalBatches = Math.ceil(CONFIG.TOTAL_LEARNERS / CONFIG.BATCH_SIZE);
  console.log(`\nâš™ï¸  Processing ${totalBatches} batches of ${CONFIG.BATCH_SIZE} learners...\n`);

  const t0 = performance.now();

  for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
    const learners = Array.from(generateLearnersStream(CONFIG.BATCH_SIZE));
    
    try {
      const result = await processBatch(learners, cache);
      metrics.successfulBatches++;
      metrics.totalTime += result.duration;
      metrics.batchTimes.push(result.duration);
      metrics.minTime = Math.min(metrics.minTime, result.duration);
      metrics.maxTime = Math.max(metrics.maxTime, result.duration);

      if (result.duration > CONFIG.SLA_MS) {
        metrics.slaBreach++;
        process.stderr.write(`âš ï¸  SLA breach: Batch ${batchIdx + 1} took ${result.duration.toFixed(2)}ms (target ${CONFIG.SLA_MS}ms)\n`);
      }

      if ((batchIdx + 1) % 10 === 0) {
        const throughput = (CONFIG.BATCH_SIZE * (batchIdx + 1)) / ((performance.now() - t0) / 60000);
        process.stderr.write(`  Batch ${batchIdx + 1}/${totalBatches} | Throughput: ${throughput.toFixed(0)} learners/min\r`);
      }
    } catch (error) {
      metrics.failedBatches++;
      console.error(`âŒ Batch ${batchIdx + 1} failed:`, error.message);
    }

    metrics.totalBatches++;
  }

  const totalDuration = performance.now() - t0;

  // Calculate statistics
  const avgTime = metrics.totalTime / metrics.successfulBatches;
  const throughput = (CONFIG.TOTAL_LEARNERS / (totalDuration / 60000));
  const p95Time = metrics.batchTimes.sort()[Math.floor(metrics.batchTimes.length * 0.95)];

  console.log('\nâœ… Test Complete\n');
  console.log('ðŸ“ˆ Throughput Metrics:');
  console.log(`  Total Learners Processed: ${CONFIG.TOTAL_LEARNERS}`);
  console.log(`  Total Batches: ${metrics.totalBatches}`);
  console.log(`  Successful: ${metrics.successfulBatches}`);
  console.log(`  Failed: ${metrics.failedBatches}`);
  console.log(`  Total Time: ${(totalDuration / 1000).toFixed(2)}s`);
  console.log(`  Throughput: ${throughput.toFixed(0)} learners/minute`);
  console.log('');
  console.log('â±ï¸  Latency Metrics:');
  console.log(`  Avg Batch Time: ${avgTime.toFixed(2)}ms`);
  console.log(`  Min Batch Time: ${metrics.minTime.toFixed(2)}ms`);
  console.log(`  Max Batch Time: ${metrics.maxTime.toFixed(2)}ms`);
  console.log(`  P95 Batch Time: ${p95Time.toFixed(2)}ms`);
  console.log(`  SLA Target: ${CONFIG.SLA_MS}ms`);
  console.log(`  SLA Breaches: ${metrics.slaBreach}/${metrics.totalBatches}`);
  console.log(`  SLA Compliance: ${(((metrics.totalBatches - metrics.slaBreach) / metrics.totalBatches) * 100).toFixed(1)}%`);
  console.log('');
  console.log('ðŸ’¾ Cache Metrics:');
  console.log(`  Hit Rate: ${cache.hitRate().toFixed(1)}%`);
  console.log(`  Hits: ${cache.hits}`);
  console.log(`  Misses: ${cache.misses}`);

  // Status
  const targetThroughput = 10000; // 10K learners/min
  const throughputOK = throughput >= targetThroughput * 0.9; // 90% of target
  const slaOK = metrics.slaBreach <= Math.ceil(metrics.totalBatches * 0.05); // <5% breaches
  
  console.log('');
  console.log('ðŸŽ¯ Acceptance Criteria:');
  console.log(`  ${throughputOK ? 'âœ…' : 'âŒ'} Throughput â‰¥ 9,000 learners/min (achieved: ${throughput.toFixed(0)})`);
  console.log(`  ${slaOK ? 'âœ…' : 'âŒ'} SLA Compliance â‰¥ 95% (achieved: ${(((metrics.totalBatches - metrics.slaBreach) / metrics.totalBatches) * 100).toFixed(1)}%)`);

  return { metrics, pass: throughputOK && slaOK };
}

/**
 * Run memory profiling test
 */
async function runMemoryTest() {
  console.log('\nðŸ’¾ Memory Usage Test');
  console.log('='.repeat(60));

  const cache = new SimpleCache(100000);
  const memBefore = process.memoryUsage();

  console.log(`Processing ${CONFIG.TOTAL_LEARNERS} learners...`);
  
  const t0 = performance.now();
  
  for (let batchIdx = 0; batchIdx < Math.ceil(CONFIG.TOTAL_LEARNERS / CONFIG.BATCH_SIZE); batchIdx++) {
    const learners = Array.from(generateLearnersStream(CONFIG.BATCH_SIZE));
    await processBatch(learners, cache);
    
    if ((batchIdx + 1) % 5 === 0) {
      process.stderr.write(`  Processed ${batchIdx + 1} batches...\r`);
    }
  }

  const duration = performance.now() - t0;
  const memAfter = process.memoryUsage();

  console.log('\nâœ… Memory Test Complete\n');
  console.log('ðŸ“Š Memory Metrics:');
  console.log(`  Heap Before: ${(memBefore.heapUsed / 1024 / 1024).toFixed(2)}MB`);
  console.log(`  Heap After: ${(memAfter.heapUsed / 1024 / 1024).toFixed(2)}MB`);
  console.log(`  Delta: ${((memAfter.heapUsed - memBefore.heapUsed) / 1024 / 1024).toFixed(2)}MB`);
  console.log(`  Peak RSS: ${(memAfter.rss / 1024 / 1024).toFixed(2)}MB`);
  console.log(`  Duration: ${(duration / 1000).toFixed(2)}s`);
}

/**
 * Main entry
 */
async function main() {
  const args = process.argv.slice(2);
  const hasLoadTest = args.includes('--load-test');
  const hasMemTest = args.includes('--memory-test');
  const hasAllTests = args.includes('--all');

  console.log('ðŸš€ Phase 3 Sprint 2 - Task 5: Performance Scaling Tests');
  console.log('Version: v1.0');
  console.log('Date:', new Date().toISOString());

  try {
    if (hasAllTests || !hasMemTest) {
      const result = await runThroughputTest();
      if (!result.pass) {
        console.log('\nâš ï¸  Some acceptance criteria not met. Review parameters.');
      }
    }

    if (hasAllTests || hasMemTest) {
      await runMemoryTest();
    }

    console.log('\nâœ… All tests completed successfully');
  } catch (error) {
    console.error('\nâŒ Test failed:', error);
    process.exit(1);
  }
}

main();
