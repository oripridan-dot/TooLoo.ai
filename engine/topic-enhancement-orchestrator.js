import { promises as fs } from 'fs';
import path from 'path';
import Summarizer from './summarizer.js';

function pickTopics(N=100){
  const base = [
    'Transformers','Reinforcement Learning','Diffusion Models','Graph Neural Networks','Few-Shot Learning','Prompt Engineering','Knowledge Distillation','Federated Learning','Self-Supervised Learning','Contrastive Learning','Transfer Learning','Active Learning','Meta-Learning','Curriculum Learning','Causal Inference','Vision-Language Models','Speech Recognition','Neural Machine Translation','Summarization','Sentiment Analysis','Topic Modeling','Anomaly Detection','Time Series Forecasting','Recommender Systems','Information Retrieval','Question Answering','Code Generation','Program Synthesis','Data Augmentation','Alignment','Safety','Bias Mitigation','Explainability','Interpretability','Multi-Agent Systems','AutoML','Hyperparameter Optimization','Bayesian Methods','Optimization','Clustering','Dimensionality Reduction','Embeddings','Tokenizer Design','Memory-Augmented Networks','Retrieval-Augmented Generation','Knowledge Graphs','Ontology Learning','Few-Shot Reasoning','Tool Use','Planning','Vision Transformers','Object Detection','Segmentation','OCR','Document QA','RLHF','DPO','Preference Learning','Adversarial Robustness','Continual Learning','Lifelong Learning','Neural Architecture Search','TinyML','Edge AI','Model Compression','Quantization','Pruning','LoRA','PEFT','Mamba','State Space Models','Mixture of Experts','Routing','Latency Optimization','GPU Optimization','Distributed Training','Sharding','Checkpointing','Data Engineering','ETL for AI','Labeling Quality','Evaluation Methodology','Benchmarks','A/B Testing for Models','Human Feedback','Synthetic Data','Simulation','Agent Evaluation','Red Teaming','Toolformer','Function Calling','Long-Context Models','Chunking Strategies','Embeddings Stores','Vector Databases','RAG Evaluation','Citation Grounding','Hallucination Reduction','Traceability','Observability','Telemetry','Cost Optimization','Energy Efficiency','Privacy Preserving ML','Differential Privacy','Homomorphic Encryption'
  ];
  const out=[]; let i=0; while(out.length<N){ out.push(base[i%base.length] + (i>=base.length? ` v${Math.floor(i/base.length)+1}`:'')); i++; }
  return out;
}

function synthesizeExample(topic, idx){
  const key = `${topic.toLowerCase().replace(/[^a-z0-9]+/g,'-')}-${idx+1}`;
  const signal = ['efficiency','robustness','accuracy','latency','throughput'][idx%5];
  const value = 50 + (idx*7)%50; // numeric value 50..99
  // Fuzzing variations
  const units = ['%', ' percent', ' pct', ' per cent'];
  const forms = [
    (v,u)=>`Topic: ${topic}. Key Insight: The ${signal} improvement measured was ${v}${u}. Further notes: ${topic} research continues to evolve. Keep the key figure visible: ${v}${u} so summarizers capture it.`,
    (v,u)=>`Measured for ${topic}: ${signal} saw a ${v}${u} boost. Notes: ${topic} shows promise. Record shows ~${v} ${u.replace(' ','')}.`,
    (v,u)=>`${signal.toUpperCase()} uplift (${topic}) registered at (${v} ${u.trim()}). Context: ${topic} pipeline indicated change ~= ${v}${u}.`,
    (v,u)=>`In ${topic}, improvement in ${signal} is ${v} ${u}. Additional commentary: ${topic} outlook is strong; ${v}${u} remains the anchor.`,
    (v,u)=>`Update: ${topic} â€” ${signal} delta recorded near ${v}${u}. Annotation(${signal}:${v}${u}).`
  ];
  const u = units[idx % units.length];
  const f = forms[idx % forms.length];
  const text = f(value, u);
  const expectedTokens = [`${value}%`]; // strict token for exact-match metric
  return { id: key, topic, text, expectedTokens, meta: { signal, value, unit: u.trim()||'%' } };
}

function extractNumbersPercent(text){
  const out=[]; const re = /(\d+(?:\.\d+)?)\s*(%|percent|pct|per\s*cent)/gi;
  let m; while((m=re.exec(text))){ out.push({ n: Number(m[1]), unit: '%' }); }
  return out;
}
function sameSentenceHasSignalAndNumber(text, signal, expected){
  const sentences = text.split(/[\.\n\r\!\?]+/);
  const sig = signal.toLowerCase();
  for (const s of sentences){
    const low = s.toLowerCase();
    if (!low.includes(sig)) continue;
    const nums = extractNumbersPercent(s);
    if (nums.some(x=> Math.abs(x.n-expected) <= 0.5)) return true;
  }
  return false;
}

export default class TopicEnhancementOrchestrator{
  constructor({ workspaceRoot=process.cwd() }={}){
    this.root = workspaceRoot;
    this.dir = path.join(workspaceRoot, 'data', 'self-enhance');
    this.summarizer = new Summarizer({ cacheDir: path.join(workspaceRoot, 'data', 'summaries-cache') });
  }

  async init(){ await fs.mkdir(this.dir, { recursive: true }); }

  async plan({ name='ai-topics', topicsCount=100, examplesPerTopic=5 }={}){
    await this.init();
    const topics = pickTopics(topicsCount);
    const examples = [];
    for (const t of topics){ for (let i=0;i<examplesPerTopic;i++){ examples.push(synthesizeExample(t, i)); } }
    const planDir = path.join(this.dir, name);
    await fs.mkdir(planDir, { recursive: true });
    await fs.writeFile(path.join(planDir, 'plan.json'), JSON.stringify({ name, topicsCount, examplesPerTopic, topics }, null, 2));
    await fs.writeFile(path.join(planDir, 'examples.jsonl'), examples.map(e=>JSON.stringify(e)).join('\n'));
    return { ok:true, name, topics: topics.length, examples: examples.length };
  }

  async run({ name='ai-topics', examples }={}){
    const planDir = path.join(this.dir, name);
    let exampleList;
    
    if (examples && Array.isArray(examples)) {
      // Use provided examples
      exampleList = examples;
    } else {
      // Try to read from file (fallback)
      try {
        const exPath = path.join(planDir, 'examples.jsonl');
        const s = await fs.readFile(exPath, 'utf8');
        exampleList = s.split(/\n/).filter(Boolean).map(line=>JSON.parse(line));
      } catch (e) {
        throw new Error(`No examples provided and could not read from file: ${e.message}`);
      }
    }
    
    const started = Date.now();
    const results=[];
    let hitsExact=0, hitsNumeric=0, hitsSignal=0, hitsStructured=0, hitsCombined=0;
    for (const ex of exampleList){
      const sum = await this.summarizer.summarize({ text: ex.text, title: ex.topic, hint:'text' });
      const raw = (typeof sum==='string'? sum : sum.text||'');
      const body = raw.toLowerCase();
      const exactOk = ex.expectedTokens.every(tok=> body.includes(tok.toLowerCase()));
      const nums = extractNumbersPercent(body);
      const numericOk = nums.some(x=> Math.abs(x.n - ex.meta.value) <= 0.5);
      const signalOk = body.includes(ex.meta.signal.toLowerCase());
      const structuredOk = sameSentenceHasSignalAndNumber(raw, ex.meta.signal, ex.meta.value);
      const combinedOk = numericOk && signalOk; // core robustness metric
      if (exactOk) hitsExact++;
      if (numericOk) hitsNumeric++;
      if (signalOk) hitsSignal++;
      if (structuredOk) hitsStructured++;
      if (combinedOk) hitsCombined++;
      results.push({ id: ex.id, topic: ex.topic, expectedTokens: ex.expectedTokens, expectedNumeric: ex.meta.value, signal: ex.meta.signal, got: raw, exactOk, numericOk, signalOk, structuredOk, combinedOk });
    }
    const durationMs = Date.now()-started;
    const total = results.length||1;
    const accuracyExact = hitsExact/total;
    const accuracyNumeric = hitsNumeric/total;
    const accuracySignal = hitsSignal/total;
    const accuracyStructured = hitsStructured/total;
    const accuracyCombined = hitsCombined/total;
    const throughput = total / (Math.max(durationMs,1)/1000);
    const run = { at: new Date().toISOString(), total, durationMs, throughput, accuracyExact, accuracyNumeric, accuracySignal, accuracyStructured, accuracyCombined, sample: results.slice(0,10) };
    const runsDir = path.join(planDir, 'runs');
    await fs.mkdir(runsDir, { recursive: true });
    const fp = path.join(runsDir, `${run.at.replace(/[:.]/g,'-')}.json`);
    await fs.writeFile(fp, JSON.stringify({ run, results }, null, 2));
    return { ok:true, name, ...run, path: fp };
  }

  async latest({ name='ai-topics' }={}){
    const planDir = path.join(this.dir, name);
    const runsDir = path.join(planDir, 'runs');
    const files = await fs.readdir(runsDir).catch(()=>[]);
    const js = files.filter(f=>f.endsWith('.json')).sort().reverse();
    if (!js.length) return { ok:true, run:null };
    const j = JSON.parse(await fs.readFile(path.join(runsDir, js[0]), 'utf8'));
    return { ok:true, run: j.run };
  }

  async planEnhancement(topicCount = 100) {
    const topics = pickTopics(topicCount);
    const examples = [];
    for (let i = 0; i < topics.length; i++) {
      for (let j = 0; j < 5; j++) {
        examples.push(synthesizeExample(topics[i], j));
      }
    }
    return { topicCount, examples: examples.length, topics, name: 'ai-topics' };
  }

  async runEnhancement(plan) {
    const topics = plan.topics || pickTopics(100);
    const examples = [];
    for (let i = 0; i < topics.length; i++) {
      for (let j = 0; j < 5; j++) {
        examples.push(synthesizeExample(topics[i], j));
      }
    }
    return await this.run({ name: plan.name || 'ai-topics', examples });
  }

  async getLatestResults() {
    return await this.latest();
  }

  async persistResults(filePath, results) {
    try {
      const dir = path.dirname(filePath);
      await fs.mkdir(dir, { recursive: true });
      await fs.writeFile(filePath, JSON.stringify(results, null, 2));
      return true;
    } catch (e) {
      console.error('Failed to persist results:', e.message);
      return false;
    }
  }
}
